---
layout: archive
title: "Projects and Publications"
permalink: projects_publications/
author_profile: true
---

<!-- <details>
<summary>
<b>  Augmented Conflict Based Search for Lifelong Agent Planning </b>
</summary>
<table style="border: none; border-collapse: collapse;">
  <tr>
    <td style="padding: 10px; border: none;">
      <div style="width: 400px; height: 300px; border-radius: 50px; overflow: hidden;">
        <img src="/portfolio/images/16782_demo.gif" alt="Project Image 2" style="width: 100%; height: 100%; object-fit: cover;">
      </div>
    </td>
    <td style="padding: 10px; border: none; vertical-align: top; font-size: 16px;">
     This project tackles the challenging Multi-Agent Pathfinding (MAPF) problem, focusing on oneshot MAPF and its dynamic counterpart, Lifelong MAPF (LMAPF). LMAPF involves agents continuously adapting to new goals, measuring performance through throughput in dynamic environments. The study also explores Conflict-Based Search Algorithm (CBS), a two-level approach addressing conflicts between agents with a Conflict Tree (CT). CBS, applied to small-scale scenarios inspired by the League of Robot Runners competition, outperforms traditional methods like A* by examining fewer states while ensuring optimality.      
      <br>
      <br>
      <a href = "https://github.com/FarStryke21/MAPF">GitHub</a> | <a href="https://farstryke21.github.io/portfolio/files/planning_project.pdf">Article</a> 
    </td>
  </tr>
</table>

</details> -->
<!-- ---

<details>
<summary>
<b> A centralised approach for Multi Agent Reinforcement Learning </b>
</summary>
<table style="border: none; border-collapse: collapse;">
  <tr>
    <td style="padding: 10px; border: none;">
      <div style="width: 400px; height: 300px; border-radius: 50px; overflow: hidden;">
        <img src="/portfolio/images/16831_project.png" alt="Project Image 2" style="width: 80%; height: 80%; object-fit: cover;">
      </div>
    </td>
    <td style="padding: 10px; border: none; vertical-align: top; font-size: 16px;">
      Our work introduces a centralized Multi-Agent Reinforcement Learning (MARL) environment for Multi-Agent Path Finding (MAPF). Built on the gymnasium-minigrid framework, our environment provides a standardized platform for benchmarking and collaborative research in the MARL community. Notable features include an efficient simulation setup for generating MAPF scenarios and a rich observation space that captures essential details like egocentric views, goal positions, agent orientations, and edge weights. Additionally, we employ a continuous action space, allowing agents to make probabilistic decisions.
      <br>
      <br>
      <a href = "https://github.com/FarStryke21/16831-Project">GitHub</a> | <a href="https://farstryke21.github.io/portfolio/files/16_831_project.pdf">Article</a> 
    </td>
  </tr>
</table>

</details> -->
---

<details>
<summary>
<b> Marine Vessel Operational Support Robot (BlackFlag) </b>
</summary>
<table style="border: none; border-collapse: collapse;">
  <tr>
    <td style="padding: 10px; border: none;">
      <div style="width: 400px; height: 300px; border-radius: 50px; overflow: hidden;">
        <img src="/portfolio/images/BlackFlag.png" alt="Project Image 2" style="width: 100%; height: 100%; object-fit: cover;">
      </div>
    </td>
    <td style="padding: 10px; border: none; vertical-align: top; font-size: 16px;">
      Developed as a part of the semester-long mechatronics capstone project, the BlackFlag utility robot represents an innovative solution for operational support on large marine vessels. The project's objective was to address the need for a robust system capable of conducting routine inspections and executing intricate operations aboard cargo vessels, while withstanding the harsh marine environment. The BlackFlag robot was equipped with a 5-degree-of-freedom (DOF) revolute arm mounted on a mobile base, complemented by a custom perception package. As a member of a five-person team, I took charge of the Perception and Sensing Subsystem, overseeing the integration of software components and the final deployment of the functional system.
      <br>
      <br>
      <a href = "https://sites.google.com/andrew.cmu.edu/shipbot-by-black-flag/home?authuser=2">Webpage</a> | <a href="https://github.com/FarStryke21/blackflag">GitHub</a> 
    </td>
  </tr>
</table>

</details>
---

<details>
<summary>
<b>Lap time optimization for Formula Style Cars</b>
</summary>
  
<table style="border: none; border-collapse: collapse;">
  <tr>
    <td style="padding: 10px; border: none;">
      <div style="width: 400px; height: 300px; border-radius: 50px; overflow: hidden;">
        <img src="/portfolio/images/laptime.png" alt="Project Image 2" style="width: 100%; height: 100%; object-fit: cover;">
      </div>
    </td>
    <td style="padding: 10px; border: none; vertical-align: top; font-size: 16px;">
      High-performance racing has always been an exciting and challenging field, where the goal is to achieve the fastest possible lap time around the track. In Formula One (F1) racing, drivers and engineers continuously search for ways to optimize the performance of their cars and outpace their competitors. One approach to improving lap times is to use optimal control strategies, which aim to find the most efficient path a racing car can take around the track. In this paper, we explore the use of optimal control strategies to model the most efficient path for a racing car to optimize its lap time around F1 circuits. Specifically, we focus on one of the iconic circuits: Monza in Italy. (Part of Optimal Control and Reinforcement Learning Capstone)
      <br>
      <br>
      <a href="https://farstryke21.github.io/portfolio/files/16745_tyagi_gite_kokil_chulawala.pdf">Article</a>
    </td>
  </tr>
</table>

</details>
---

<details>
<summary>
<b>Panel Gap Identification for Automobiles</b>
</summary>
<table style="border: none; border-collapse: collapse;">
  <tr>
    <td style="padding: 10px; border: none;">
      <div style="width: 400px; height: 300px; border-radius: 50px; overflow: hidden;">
        <img src="/portfolio/images/panelgap.png" alt="Project Image 2" style="width: 100%; height: 100%; object-fit: cover;">
      </div>
    </td>
    <td style="padding: 10px; border: none; vertical-align: top; font-size: 16px;">
      Panel gaps in automobiles refer to the spaces or misalignments between adjacent body panels. Addressing these gaps is crucial as they impact the vehicle's aesthetics, structural integrity, and aerodynamics. Well-aligned panels also contribute to enhanced water and dust resistance, reduced noise levels, and increased resale value. Notably, automobile manufacturers allocate significant resources annually to recall and rectify cars affected by panel gap errors. To combat this issue, our team embarked on the development of a novel solution: a system capable of identifying and classifying panel gap defects using a stereo depth camera on the shop floor. This innovative approach was prototyped as part of the Computer Vision Capstone project. As a team of three, we successfully demonstrated our prototypes and defended our work in front of a panel of our peers and instructors.
      <br>
      <br>
      <a href="https://github.com/FarStryke21/Panel_Gap_Detection">GitHub</a>
    </td>
  </tr>
</table>
</details>
---
<details>
<summary>
<b>Visual Odometry through RNNs</b>
</summary>
<table style="border: none; border-collapse: collapse;">
  <tr>
    <td style="padding: 10px; border: none;">
      <div style="width: 400px; height: 300px; border-radius: 50px; overflow: hidden;">
        <img src="/portfolio/images/odometry.png" alt="Project Image 2" style="width: 100%; height: 100%; object-fit: cover;">
      </div>
    </td>
    <td style="padding: 10px; border: none; vertical-align: top; font-size: 16px;">
      The standard pipeline for performing visual odometry includes feature extraction, camera calibration,local optimisation etc. Thus some prior knowledge of system is required to recover absolute trajectory. However,a RNN+CNN model can be used to infer poses directly without this prior knowledge. This report presents comparison between the conventional method (geometry-based odometry) used for monocular visual odometry with an end-to-end trained RNN+CNN model for trajectory estimation and verifies the viability of the end-to-end model over traditional visual odometry systems. (Capstone for Machine Learning and Artificial Intelligence)
      <br>
      <br>
      <a href="https://farstryke21.github.io/portfolio/files/Visual_Odometry.pdf">Article</a>
    </td>
  </tr>
</table>
</details>
---

